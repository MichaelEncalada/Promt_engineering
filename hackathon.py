# -*- coding: utf-8 -*-
"""Hackathon.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1rTZ2d9C66_qNqfc8LstFwujXWbUW0C3N

# **Propuesta**
"""

!pip install openai

!pip install openai tiktoken pypdf chromadb langchain

# Commented out IPython magic to ensure Python compatibility.
#%pip install langchain openai pypdf python-dotenv chromadb  tiktoken -q
# Install Requirements
!apt-get -qq install poppler-utils tesseract-ocr
# Upgrade Pillow to latest version
# %pip install -q --user --upgrade pillow
# Install Python Packages
# %pip install -q unstructured["all-docs"]==0.12.0 langchain openai tiktoken beautifulsoup4 chromadb ragas datasets pinecone-client pinecone-text

# NOTE: you may also upgrade to the latest version with the command below,
#       though a more recent version of unstructured will not have been tested with this notebook
# %pip install -q --upgrade unstructured

#!pip install openai
import getpass, openai, os
api_key = getpass.getpass(prompt="OPENAI - KEY: ")
openai.apikey = api_key
os.environ["OPENAI_API_KEY"] = api_key

import getpass, openai, os
from langchain.document_loaders import PyPDFLoader
from langchain.vectorstores import Chroma
from langchain.embeddings.openai import OpenAIEmbeddings
from langchain.chat_models import ChatOpenAI
from langchain.chains import RetrievalQA as RQa
!pip install pillow-heif

import requests

import requests

# Lista de URLs para cada mes
urls = [
    r"https://www.defensoria.gob.pe/wp-content/uploads/2023/02/Reporte-Mensual-de-Conflictos-Sociales-N°-227-Enero-2023.pdf",
    r"https://www.defensoria.gob.pe/wp-content/uploads/2023/03/Reporte-Mensual-de-Conflictos-Sociales-N°-228-Febrero-2023.pdf",
    r"https://www.defensoria.gob.pe/wp-content/uploads/2023/04/Reporte-Mensual-de-Conflictos-Sociales-N-229-Marzo-2023.pdf",
    r"https://www.defensoria.gob.pe/wp-content/uploads/2023/05/Reporte-Mensual-de-Conflictos-Sociales-N230_Abril-2023.pdf",
    r"https://www.defensoria.gob.pe/wp-content/uploads/2023/06/Reporte-Mensual-de-Conflictos-Sociales-N°-231-mayo-2023.pdf",
    r"https://www.defensoria.gob.pe/wp-content/uploads/2023/07/Reporte-Mensual-de-Conflictos-Sociales-N°-232-Junio-2023.pdf",
    r"https://www.defensoria.gob.pe/wp-content/uploads/2023/08/Reporte-Mensual-de-Conflictos-Sociales-N°-233-Julio-2023.pdf",
    r"https://www.defensoria.gob.pe/wp-content/uploads/2023/09/Reporte-Mensual-de-Conflictos-Sociales-N°-234-Agosto-2023.pdf",
    r"https://www.defensoria.gob.pe/wp-content/uploads/2023/10/Reporte-Mensual-de-Conflictos-Sociales-N°-235-Setiembre-2023.pdf",
    r"https://www.defensoria.gob.pe/wp-content/uploads/2023/11/Reporte-Mensual-de-Conflictos-Sociales-N°-236-Octubre-2023.pdf",
    r"https://www.defensoria.gob.pe/wp-content/uploads/2023/12/Reporte-Mensual-de-Conflictos-Sociales-N°-237-Noviembre-2023.pdf",
    r"https://www.defensoria.gob.pe/wp-content/uploads/2024/01/Reporte-Mensual-de-Conflictos-Sociales-N°-238-Diciembre-2023.pdf",
]

# Iterar sobre las URLs para descargar los archivos PDF
for i, url in enumerate(urls, start=1):
    response = requests.get(url)
    file_name = f"month_{i}_2023.pdf"  # Nombre del archivo basado en el índice
    with open(file_name, "wb") as document:
        document.write(response.content)

"""# Scrapeo de PDFs"""

import tiktoken
tokenizer = tiktoken.get_encoding("cl100k_base")

def tokenCounter(text):
    return len(tokenizer.encode(text))

def pdfToString(path):
    documentText = ""
    loadedPdf = PdfReader(path)
    for page in loadedPdf.pages:
        documentText += page.extract_text()
    return documentText

!pip install PyPDF2

from PyPDF2 import PdfReader
month_1_2023 = pdfToString("month_1_2023.pdf")
month_2_2023 = pdfToString("month_2_2023.pdf")
month_3_2023 = pdfToString("month_3_2023.pdf")
month_4_2023 = pdfToString("month_4_2023.pdf")
month_5_2023 = pdfToString("month_5_2023.pdf")
month_6_2023 = pdfToString("month_6_2023.pdf")
month_7_2023 = pdfToString("month_7_2023.pdf")
month_8_2023 = pdfToString("month_8_2023.pdf")
month_9_2023 = pdfToString("month_9_2023.pdf")
month_10_2023 = pdfToString("month_10_2023.pdf")
month_11_2023 = pdfToString("month_11_2023.pdf")
month_12_2023 = pdfToString("month_12_2023.pdf")

lista_c=[chunks_enero_2023[0], chunks_febrero_2023[0], chunks_marzo_2023[0], chunks_abril_2023[0], chunks_mayo_2023[0], chunks_junio_2023[0], chunks_julio_2023[0], chunks_agosto_2023[0], chunks_septiembre_2023[0], chunks_octubre_2023[0], chunks_noviembre_2023[0], chunks_diciembre_2023[0]]

def tokenCounter(text):
    return len(tokenizer.encode(text))

chunks_enero_2023[0]

!pip install langchain

from langchain.text_splitter import RecursiveCharacterTextSplitter


textSplitter = RecursiveCharacterTextSplitter(
    chunk_size=8192,
    chunk_overlap=50,
    length_function=tokenCounter,
    separators = ["\n\n", ".", "\n", " "]
)

chunks_enero_2023 = textSplitter.create_documents(
    [month_1_2023],
    metadatas=[{ "año": "2022", "mes": "enero"}]
)

chunks_febrero_2023 = textSplitter.create_documents(
    [month_2_2023],
    metadatas=[{ "año": "2022", "mes": "febrero"}]
)

chunks_marzo_2023 = textSplitter.create_documents(
    [month_3_2023],
    metadatas=[{ "año": "2022", "mes": "marzo"}]
)

chunks_abril_2023 = textSplitter.create_documents(
    [month_4_2023],
    metadatas=[{ "año": "2022", "mes": "abril"}]
)

chunks_mayo_2023 = textSplitter.create_documents(
    [month_5_2023],
    metadatas=[{ "año": "2022", "mes": "mayo"}]
)

chunks_junio_2023 = textSplitter.create_documents(
    [month_6_2023],
    metadatas=[{ "año": "2022", "mes": "junio"}]
)

chunks_julio_2023 = textSplitter.create_documents(
    [month_7_2023],
    metadatas=[{ "año": "2022", "mes": "julio"}]
)

chunks_agosto_2023 = textSplitter.create_documents(
    [month_8_2023],
    metadatas=[{ "año": "2022", "mes": "agosto"}]
)
chunks_septiembre_2023 = textSplitter.create_documents(
    [month_9_2023],
    metadatas=[{ "año": "2022", "mes": "septiembre"}]
)
chunks_octubre_2023 = textSplitter.create_documents(
    [month_10_2023],
    metadatas=[{ "año": "2022", "mes": "octubre"}]
)

chunks_noviembre_2023 = textSplitter.create_documents(
    [month_11_2023],
    metadatas=[{ "año": "2022", "mes": "noviembre"}]
)

chunks_diciembre_2023 = textSplitter.create_documents(
    [month_12_2023],
    metadatas=[{ "año": "2022", "mes": "diciembre"}]
)

print(chunks_diciembre_2023[0].page_content)

"""#### **Embedding**"""

#%pip install langchain openai pypdf python-dotenv chromadb  tiktoken -q
import getpass, openai, os

os.listdir()

from langchain_openai import OpenAIEmbeddings

# Crear una instancia de OpenAIEmbeddings
embedding = OpenAIEmbeddings()

# Lista para almacenar los embeddings de todos los fragmentos
embeddings_all_chunks = []

# Definir una función para convertir un archivo PDF en texto
def pdf_to_text(path):
    text = ""
    with open(path, 'rb') as file:
        reader = PdfReader(file)
        for page in reader.pages:
            text += page.extract_text()
    return text

# Iterar sobre los documentos PDF de cada mes y realizar el embedding
all_chunks = chunks_enero_2023+ chunks_febrero_2023 + chunks_marzo_2023 + chunks_abril_2023 + chunks_mayo_2023 + chunks_junio_2023 + chunks_julio_2023 + chunks_agosto_2023 + chunks_septiembre_2023 + chunks_octubre_2023 + chunks_noviembre_2023 + chunks_diciembre_2023
for pdf_text in all_chunks:


    # Realizar el embedding del texto completo del mes
    month_embedding = embedding.embed_documents([pdf_text.page_content])[0]

    # Almacenar el embedding
    embeddings_all_chunks.append(month_embedding)

# Verificar la longitud de los embeddings generados
print("Número de embeddings generados:", len(embeddings_all_chunks))

len(all_chunks)

embeddings_all_chunks[]

from langchain.chat_models import ChatOpenAI
from langchain.chains import RetrievalQA as RQa

llm_model = "gpt-4-turbo-preview"
llm = ChatOpenAI(model_name=llm_model, temperature=0.5)
question = "¿Cuantas protestas hubieron en enero del 2023?"

from langchain.vectorstores import Chroma

persist_directory = './vector_db_chroma/'

!rm -rf ./docs/chroma  # remove old database files if any

vectordb = Chroma.from_documents(
    documents=lista_c,
    embedding=embedding,
    persist_directory=persist_directory
)

print(vectordb._collection.count())

question = "¿Que patrones encuentras en las protestas en la provincia de Apurimac?"
retriever = vectordb.as_retriever()
docs = retriever.get_relevant_documents(question)
docs

m_p = RQa.from_chain_type(
    llm, retriever=vectordb.as_retriever(),
    chain_type="map_reduce"
)
mp_result = m_p({"query": question})
mp_result['result']

"""# **Interfaz usuario**"""

#!pip install streamlit

import streamlit as st

while True:
    question = input("Ask: ")
    if question == "":
        break
    stuff = RQa.from_chain_type(
        llm, retriever = vectordb.as_retriever(),
        chain_type = "stuff" # default
    )
    stuff_result = stuff({"query": question})
    result = stuff_result['result']
    format_response = f"""
    Question:
      {question}
    Result:
      {result}
    ------------ x -------------
    """
    print(format_response)

# example questions:
# cómo afectan los choques de política fiscal no anticipados a la economía?
# la política monetaria afecta de manera distinta a sectores distintos?
# cómo afectan los acuerdos comerciales al valor de las exportaciones?

import streamlit as st
from dotenv import load_dotenv
import pickle
from PyPDF2 import PdfReader
from streamlit_extras.add_vertical_space import add_vertical_space
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.embeddings.openai import OpenAIEmbeddings
from langchain.vectorstores import FAISS
from langchain.llms import OpenAI
from langchain.chains.question_answering import load_qa_chain
from langchain.callbacks import get_openai_callback
import os

# Sidebar contents
with st.sidebar:
    st.title('🤗💬 LLM Chat App')
    st.markdown('''
    ## About
    This app is an LLM-powered chatbot built using:
    - [Streamlit](https://streamlit.io/)
    - [LangChain](https://python.langchain.com/)
    - [OpenAI](https://platform.openai.com/docs/models) LLM model

    ''')
    add_vertical_space(5)
    st.write('Made with ❤️ by [Prompt Engineer](https://youtube.com/@engineerprompt)')

load_dotenv()

def main():
    st.header("Chat with PDF 💬")


    # upload a PDF file
    pdf = st.file_uploader("Upload your PDF", type='pdf')

    # st.write(pdf)
    if pdf is not None:
        pdf_reader = PdfReader(pdf)

        text = ""
        for page in pdf_reader.pages:
            text += page.extract_text()

        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,
            chunk_overlap=200,
            length_function=len
            )
        chunks = text_splitter.split_text(text=text)

        # # embeddings
        store_name = pdf.name[:-4]
        st.write(f'{store_name}')
        # st.write(chunks)

        if os.path.exists(f"{store_name}.pkl"):
            with open(f"{store_name}.pkl", "rb") as f:
                VectorStore = pickle.load(f)
            # st.write('Embeddings Loaded from the Disk')s
        else:
            embeddings = OpenAIEmbeddings()
            VectorStore = FAISS.from_texts(chunks, embedding=embeddings)
            with open(f"{store_name}.pkl", "wb") as f:
                pickle.dump(VectorStore, f)

        # embeddings = OpenAIEmbeddings()
        # VectorStore = FAISS.from_texts(chunks, embedding=embeddings)

        # Accept user questions/query
        query = st.text_input("Ask questions about your PDF file:")
        # st.write(query)

        if query:
            docs = VectorStore.similarity_search(query=query, k=3)

            llm = OpenAI()
            chain = load_qa_chain(llm=llm, chain_type="stuff")
            with get_openai_callback() as cb:
                response = chain.run(input_documents=docs, question=query)
                print(cb)
            st.write(response)

if __name__ == '__main__':
    main()
Tags:
Advertisement
Comments
mahdibk
MAHDIBK
242 DAYS
  0.49 KB |

What color is the sky? - How to add custom templates to load_qa_chain?

This is actually important to add. If you ask about unrelated topic, like "What color is the sky", it will still answer related to the video...

I tried combine_docs_chain_kwargs={"prompt": prompt} with no success. Also, I can't make the code work with LLMChain, like:

` chat_prompt = ChatPromptTemplate.from_messages(
[system_message_prompt, human_message_prompt]
)

chain = LLMChain(llm=chat, prompt=chat_prompt)`